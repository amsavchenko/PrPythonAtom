{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Мои Фамилия Имя: Савченко Антон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Загрузите датасет titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Обратите внимание на разное количество значений переменных\n",
    "Если это так - то у вас пропуски в данных. Такое бывает. \n",
    "Например в этом датасете не получилось выяснить всех подробностей у некоторых людей в виду утери данных, невозможности узнать или восстановить их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Давайте возьмем для начала только несколько признаков, позже - вы увеличите их количество и сделаете соответствующую обработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Sex', 'Age', 'Pclass', 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train = df_titanic[columns].loc[:500]\n",
    "simple_test = df_titanic[columns].loc[500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> мы пока не умеем на уровне алгоритма работать с пропущенными значениями. \n",
    "Представьте вам дают 5-мерный вектор у которого заполнены только три компоненты и другой такой же вектор но у него заполнены лишь две  компоненты.  Как померить их сходство????\n",
    "\n",
    "distance_between( [1,0,1, NaN, NaN], [NaN, 1, 1, NaN, NaN] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> один из вариантов - заполнить какими то значениями - например если это возраст - то заполнить средним по датасету или нулем.\n",
    "\n",
    ">> на будущее - в sklearn есть такой модуль - http://scikit-learn.org/stable/modules/impute.html но сейчас можете заполнить пропуски средствами pandas - метод fillna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Заполните пропущенные значения чем нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train = simple_train.fillna(0)\n",
    "simple_test = simple_test.fillna(0)\n",
    "\n",
    "\n",
    "# можно inplace делать такое, а можно переприсваивать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> мы чемпионы. Но мы понимаем, что алгоритм у нас метрический - он не понимает как померить близость векторов в которых содержатся строки\n",
    "\n",
    "distance( [1,1,0,'мужик'], [1, 0, 1, 'принцесска'] )\n",
    "\n",
    "> поэтому давайте заведем признак is_man который будет принимать значение 0 или 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Заведите бинарный признак отвечающий за пол. Строковый удалите\n",
    "\n",
    "хинт - есть метод apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train = simple_train.rename({'Sex': 'is_man'}, axis='columns')\n",
    "simple_train['is_man'] = simple_train['is_man'].apply(lambda x: 1 if x=='male' else 0)\n",
    "simple_test = simple_test.rename({'Sex': 'is_man'}, axis='columns')\n",
    "simple_test['is_man'] = simple_test['is_man'].apply(lambda x: 1 if x=='male' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сформируйте трейн и тест выборку, где в X лежат признаки 'Sex', 'Age', 'Pclass', а в у - Survived\n",
    "\n",
    "Результат - numpy array\n",
    "\n",
    "hint - у pandas есть метод drop() и атрибут values; Пощупайте их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = simple_train[['is_man', 'Age', 'Pclass']].values\n",
    "X_test = simple_test.drop(columns='Survived').values\n",
    "y_train = simple_train['Survived'].values\n",
    "y_test = simple_test['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 501 entries, 0 to 500\n",
      "Data columns (total 4 columns):\n",
      "is_man      501 non-null int64\n",
      "Age         501 non-null float64\n",
      "Pclass      501 non-null int64\n",
      "Survived    501 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 15.7 KB\n"
     ]
    }
   ],
   "source": [
    "simple_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(X_train, np.ndarray)\n",
    "assert isinstance(X_test, np.ndarray)\n",
    "assert isinstance(y_train, np.ndarray)\n",
    "assert isinstance(y_test, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(X_train)), 'у вас в данных есть пропущенные значения. Заполните их или удалите'\n",
    "assert not np.any(np.isnan(X_test)), 'у вас в данных есть пропущенные значения. Заполните их или удалите'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Реализуйте KNN. Сами, как делали это на лекции. \n",
    "\n",
    "Можете улучшить его.\n",
    "(например использовать kd-tree для быстрого поиска ближайших соседей, \n",
    " или обходить соседей и класть расстояния в мин-кучу - тогда вы быстрее будете набирать их, без сортировки.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"\n",
    "    simple KNN classifier with O(n) complexity for memory,\n",
    "    and O(n log n) complexity - for nn search.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_hat = []\n",
    "        assert len(X.shape) == 2\n",
    "        for (sex, age, pclass) in X:\n",
    "            distance = np.sqrt((self.X[:,0]-sex)**2 + (self.X[:,1]-age)**2 + (self.X[:,2]-pclass)**2)\n",
    "            good_idxs = np.argsort(distance)[:self.n] \n",
    "            prediction = np.argmax(np.bincount(self.y[good_idxs]))\n",
    "            y_hat.append(prediction)\n",
    "        \n",
    "        return np.array(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN(5)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### посчитайте руками (не используя sklearn) качество вашего предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "доля правильных ответов: 0.7698209718670077\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(y_pred == y_test)\n",
    "print('доля правильных ответов:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Мы получили бейслайн решение. Оно должно давать скорр в районе 0.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7698209718670077\n"
     ]
    }
   ],
   "source": [
    "### можете проверить себя\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf=KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "np.unique(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO продолжение домашки"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1) Добавьте еще признаков. Как минимум хочется чтобы вы добавили в X такие признаки как Cabin, Fare и Embarked.\n",
    "\n",
    "2) Предобработайте признаки для нашего алгоритма. Поминим - что он (метрический) основан на том, что мы будем считать расстояния. \n",
    "Для этого нужно подготовить данные соответственно - привести к одному масштабу и проч. \n",
    "(https://sebastianraschka.com/Articles/2014_about_feature_scaling.html#about-standardization)\n",
    "\n",
    "Когда мы делаем такие преобразования - хочется чтобы знания и любая статистика о тесте не проникали в обучение - \n",
    "иначе будет проблема data leakage, а она в свою очередь приведет к переобучению.\n",
    "\n",
    "Поэтому аккуратно делим на трейн-тест (можно на трейн-валидацию-тест) считаем статистики на обучающей части и применяем их к тестовой.\n",
    "\n",
    "\n",
    "3) Дальше. Признаки с пропусками - вы знаете что делать. Нужно проявить фантазию и погуглить как их правильно заполнять.\n",
    "\n",
    "4) Признаки бывают непрерывными и категориальными. К категориальным признакам можно отнести например строки, тип палубы и прочее.\n",
    "Как их предобрабатывать - зависит от алгоритма. \n",
    "Самый простой способ, что сделать с категориальными признаками - представить в виде dummy признаков - так называемый one hot encoding.\n",
    "\n",
    "4) признак Cabin мб может помочь, но нужно проявить фантазию и вытащить что нибудь полезное.\n",
    "Например - вытащить оттуда тип палубы.\n",
    "\n",
    "5) Попробуйте разбить данные на три части (трейн-валидацию-тест) и подобрать гиперпараметр - число ближайших соседей. \n",
    "Как вариант можно выбирать на валидации алгоритм который дал наилучший скорр, а затем посмотреть его качество на тесте.\n",
    "\n",
    "6) советоваться друг с другом можно. Списывать нельзя. Читайте треды kaggle. Спрашивайте преподавателей! Запилите крутые фичи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим колонку FamilySize\n",
    "df_titanic['FamilySize'] = df_titanic['SibSp'] + df_titanic['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 601 entries, 0 to 600\n",
      "Data columns (total 8 columns):\n",
      "Sex           601 non-null object\n",
      "Age           475 non-null float64\n",
      "Pclass        601 non-null int64\n",
      "Survived      601 non-null int64\n",
      "Cabin         137 non-null object\n",
      "Fare          601 non-null float64\n",
      "Embarked      600 non-null object\n",
      "FamilySize    601 non-null int64\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 37.6+ KB\n"
     ]
    }
   ],
   "source": [
    "new_columns = ['Sex', 'Age', 'Pclass', 'Survived', 'Cabin', 'Fare', 'Embarked', 'FamilySize']\n",
    "new_train = df_titanic[new_columns].loc[:600]\n",
    "new_test = df_titanic[new_columns].loc[600:740]\n",
    "validation = df_titanic[new_columns].loc[740:]\n",
    "\n",
    "new_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = new_train.rename({'Sex': 'is_man'}, axis='columns')\n",
    "new_train['is_man'] = new_train['is_man'].apply(lambda x: 1 if x=='male' else 0)\n",
    "\n",
    "new_test = new_test.rename({'Sex': 'is_man'}, axis='columns')\n",
    "new_test['is_man'] = new_test['is_man'].apply(lambda x: 1 if x=='male' else 0)\n",
    "\n",
    "validation = validation.rename({'Sex': 'is_man'}, axis='columns')\n",
    "validation['is_man'] = validation['is_man'].apply(lambda x: 1 if x=='male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# не хватает данных в age, cabin, embarked\n",
    "new_train['Age'] = new_train['Age'].fillna(new_train.Age.mean())\n",
    "new_test['Age'] = new_test['Age'].fillna(new_test.Age.mean())\n",
    "validation['Age'] = validation['Age'].fillna(validation.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только первую букву каюты, тк она означает палубу, 1 класс A-E, 2 D-F, 3 E-G \n",
    "\n",
    "new_train['Cabin'] = new_train.Cabin.str[0]\n",
    "new_train['Cabin'] = new_train['Cabin'].fillna('X')\n",
    "\n",
    "new_test['Cabin'] = new_test.Cabin.str[0]\n",
    "new_test['Cabin'] = new_test['Cabin'].fillna('X')\n",
    "\n",
    "validation['Cabin'] = validation.Cabin.str[0]\n",
    "validation['Cabin'] = validation['Cabin'].fillna('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.groupby('Embarked').size()\n",
    "# в пункте отправления пропусков совсем немного, заполним самым часто встречающимся S\n",
    "\n",
    "new_train['Embarked'] = new_train['Embarked'].fillna('S')\n",
    "new_test['Embarked'] = new_test['Embarked'].fillna('S')\n",
    "validation['Embarked'] = validation['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S -> 0, C -> 1, Q -> 2\n",
    "new_train['Embarked'] = new_train['Embarked'].apply(lambda x: 0 if x=='S' else 1 if x=='C' else 2)\n",
    "new_test['Embarked'] = new_test['Embarked'].apply(lambda x: 0 if x=='S' else 1 if x=='C' else 2)\n",
    "validation['Embarked'] = validation['Embarked'].apply(lambda x: 0 if x=='S' else 1 if x=='C' else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# one hot encoding Embarked\\nembarked_dummies = pd.get_dummies(new_train.Embarked, prefix=\"Embarked\")\\nnew_train = new_train.drop(columns=\\'Embarked\\')\\nnew_train = pd.concat([new_train, embarked_dummies], axis=1)\\n\\nembarked_dummies = pd.get_dummies(new_test.Embarked, prefix=\"Embarked\")\\nnew_test = new_test.drop(columns=\\'Embarked\\')\\nnew_test = pd.concat([new_test, embarked_dummies], axis=1)\\n\\nembarked_dummies = pd.get_dummies(validation.Embarked, prefix=\"Embarked\")\\nvalidation = validation.drop(columns=\\'Embarked\\')\\nvalidation = pd.concat([validation, embarked_dummies], axis=1)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# one hot encoding Embarked\n",
    "embarked_dummies = pd.get_dummies(new_train.Embarked, prefix=\"Embarked\")\n",
    "new_train = new_train.drop(columns='Embarked')\n",
    "new_train = pd.concat([new_train, embarked_dummies], axis=1)\n",
    "\n",
    "embarked_dummies = pd.get_dummies(new_test.Embarked, prefix=\"Embarked\")\n",
    "new_test = new_test.drop(columns='Embarked')\n",
    "new_test = pd.concat([new_test, embarked_dummies], axis=1)\n",
    "\n",
    "embarked_dummies = pd.get_dummies(validation.Embarked, prefix=\"Embarked\")\n",
    "validation = validation.drop(columns='Embarked')\n",
    "validation = pd.concat([validation, embarked_dummies], axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# one hot encoding Cabin\\ncabin_dummies = pd.get_dummies(new_train.Cabin, prefix=\"Cabin\")\\nnew_train = new_train.drop(columns=\\'Cabin\\')\\nnew_train = pd.concat([new_train, cabin_dummies], axis=1)\\n\\ncabin_dummies = pd.get_dummies(new_test.Cabin, prefix=\"Cabin\")\\nnew_test = new_test.drop(columns=\\'Cabin\\')\\nnew_test = pd.concat([new_test, cabin_dummies], axis=1)\\n\\ncabin_dummies = pd.get_dummies(validation.Cabin, prefix=\"Cabin\")\\nvalidation = validation.drop(columns=\\'Cabin\\')\\nvalidation = pd.concat([validation, cabin_dummies], axis=1)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# one hot encoding Cabin\n",
    "cabin_dummies = pd.get_dummies(new_train.Cabin, prefix=\"Cabin\")\n",
    "new_train = new_train.drop(columns='Cabin')\n",
    "new_train = pd.concat([new_train, cabin_dummies], axis=1)\n",
    "\n",
    "cabin_dummies = pd.get_dummies(new_test.Cabin, prefix=\"Cabin\")\n",
    "new_test = new_test.drop(columns='Cabin')\n",
    "new_test = pd.concat([new_test, cabin_dummies], axis=1)\n",
    "\n",
    "cabin_dummies = pd.get_dummies(validation.Cabin, prefix=\"Cabin\")\n",
    "validation = validation.drop(columns='Cabin')\n",
    "validation = pd.concat([validation, cabin_dummies], axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# новый kNN с учетом добавленных параметров\n",
    "\n",
    "#['Sex', 'Age', 'Pclass', 'Fare', 'FamilySize', e0, e1, e2, ]\n",
    "\n",
    "class better_KNN:\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_hat = []\n",
    "        assert len(X.shape) == 2\n",
    "        for (sex, age, pclass, fare, famsize) in X: # embarked_0, embarked_1, embarked_2) in X:\n",
    "            distance = np.sqrt( (self.X[:,0]-sex)**2 + (self.X[:,1]-age)**2 + (self.X[:,2]-pclass)**2 + \n",
    "                                (self.X[:,3]-fare)**2 + (self.X[:,4]-famsize)**2 ) #+ \n",
    "                                #(self.X[:,5]-embarked_0)**2 + (self.X[:,6]-embarked_1)**2 + (self.X[:,7]-embarked_2)**2 )  \n",
    "            \n",
    "            good_idxs = np.argsort(distance)[:self.n] \n",
    "            prediction = np.argmax(np.bincount(self.y[good_idxs]))\n",
    "            y_hat.append(prediction)\n",
    "        \n",
    "        return np.array(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "делал one hot encoding для Cabin и проверял - на результат никак не влияет, так что без него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_train.drop(columns=['Survived', 'Cabin', 'Embarked']).values\n",
    "X_test = new_test.drop(columns=['Survived', 'Cabin', 'Embarked']).values\n",
    "X_valid = validation.drop(columns=['Survived', 'Cabin', 'Embarked']).values\n",
    "\n",
    "y_train = new_train['Survived'].values\n",
    "y_test = new_test['Survived'].values\n",
    "y_valid = validation['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7549668874172185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#for i in range(5)\n",
    "knn = better_KNN(22)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_valid)\n",
    "print(accuracy_score(y_valid, y_pred), sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 0.7549668874172185)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for i in range(3,600):\n",
    "    knn = better_KNN(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    d[i] = acc\n",
    "best_k = 0\n",
    "best_score = 0\n",
    "for i in d.items():\n",
    "    if i[1] > best_score:\n",
    "        best_score, best_k = i[1],i[0]\n",
    "\n",
    "best_k, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с Embarked и без него получился одинаковый скорр (но при разных k(22/14)) - 0.7549668874172185,так что от него тоже избавился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0.8543046357615894)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min-Max Scaling\n",
    "max_ = X_train.max(axis=0)\n",
    "min_ = X_train.min(axis=0)\n",
    "\n",
    "X_train = (X_train - min_) / (max_ - min_)\n",
    "X_valid = (X_valid - min_) / (max_ - min_)\n",
    "\n",
    "d = {}\n",
    "for i in range(3,600):\n",
    "    knn = better_KNN(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    d[i] = acc\n",
    "best_k = 0\n",
    "best_score = 0\n",
    "for i in d.items():\n",
    "    if i[1] > best_score:\n",
    "        best_score, best_k = i[1],i[0]\n",
    "\n",
    "best_k, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "после Min-Max scaling скорр возрос до 0.8543046357615894 при k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Standartization\\nmean_ = X_train.mean(axis=0)\\nstd_ = X_train.std(axis=0)\\n\\nX_train = (X_train - mean_) / std_\\nX_valid = (X_valid - mean_) / std_\\n\\nd = {}\\nfor i in range(3,600):\\n    knn = better_KNN(i)\\n    knn.fit(X_train,y_train)\\n    y_pred = knn.predict(X_valid)\\n    acc = accuracy_score(y_valid, y_pred)\\n    d[i] = acc\\nbest_k = 0\\nbest_score = 0\\nfor i in d.items():\\n    if i[1] > best_score:\\n        best_score, best_k = i[1],i[0]\\n\\nbest_k, best_score \\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Standartization\n",
    "mean_ = X_train.mean(axis=0)\n",
    "std_ = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean_) / std_\n",
    "X_valid = (X_valid - mean_) / std_\n",
    "\n",
    "d = {}\n",
    "for i in range(3,600):\n",
    "    knn = better_KNN(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_valid)\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    d[i] = acc\n",
    "best_k = 0\n",
    "best_score = 0\n",
    "for i in d.items():\n",
    "    if i[1] > best_score:\n",
    "        best_score, best_k = i[1],i[0]\n",
    "\n",
    "best_k, best_score \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "после стандартизованной оценки (standartization) скорр упал до 0.847682119205298 (k=4), можно сделать вывод что в нашем случае лучше работает шкалирование (Min-Max Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0.8368794326241135)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим min-max scaling на тесте\n",
    "\n",
    "#max_ = X_train.max(axis=0)\n",
    "#min_ = X_train.min(axis=0)\n",
    "                                    # уже посчитано выше\n",
    "#X_train = (X_train - min_) / (max_ - min_)\n",
    "X_test = (X_test - min_) / (max_ - min_)\n",
    "\n",
    "d = {}\n",
    "for i in range(3,600):\n",
    "    knn = better_KNN(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    d[i] = acc\n",
    "best_k = 0\n",
    "best_score = 0\n",
    "for i in d.items():\n",
    "    if i[1] > best_score:\n",
    "        best_score, best_k = i[1],i[0]\n",
    "\n",
    "best_k, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min-Max на тесте: 0.8368794326241135 при k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# проверим standarization на тесте\\n\\nmean_ = X_train.mean(axis=0)\\nstd_ = X_train.std(axis=0)\\n\\nX_train = (X_train - mean_) / std_\\nX_test = (X_test - mean_) / std_\\n\\nd = {}\\nfor i in range(3,600):\\n    knn = better_KNN(i)\\n    knn.fit(X_train,y_train)\\n    y_pred = knn.predict(X_test)\\n    acc = accuracy_score(y_test, y_pred)\\n    d[i] = acc\\nbest_k = 0\\nbest_score = 0\\nfor i in d.items():\\n    if i[1] > best_score:\\n        best_score, best_k = i[1],i[0]\\n\\nbest_k, best_score \\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# проверим standarization на тесте\n",
    "\n",
    "mean_ = X_train.mean(axis=0)\n",
    "std_ = X_train.std(axis=0)\n",
    "\n",
    "X_train = (X_train - mean_) / std_\n",
    "X_test = (X_test - mean_) / std_\n",
    "\n",
    "d = {}\n",
    "for i in range(3,600):\n",
    "    knn = better_KNN(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    d[i] = acc\n",
    "best_k = 0\n",
    "best_score = 0\n",
    "for i in d.items():\n",
    "    if i[1] > best_score:\n",
    "        best_score, best_k = i[1],i[0]\n",
    "\n",
    "best_k, best_score \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Std на тесте тоже 0.8368794326241135 (при k = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что в итоге "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) добавлена колонка FamilySize (по советам с тредов на kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) добавлены новые признаки: 'Sex', 'Age', 'Pclass', 'Cabin', 'Fare', 'Embarked', 'FamilySize'. Заполнены пропуски в  данных. В Cabin оставлена только буква, указывающая на палубу. Категориальные Cabin и Embarked представлены в виде dummy-признаков (one hot encoding), но на скорр они никак не повлияли, поэтомы были убраны.\n",
    "\n",
    "3) для валидации попробовал min-max scaling и standartization, лучший результат дало шкалирование.\n",
    "\n",
    "4) применил его для теста -- результат: 0.8368794326241135 при k = 5\n",
    "\n",
    "5) на этом, как я понял, задания заканчиваются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
